{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b968d1",
   "metadata": {},
   "source": [
    "# **BÁO CÁO BÀI THỰC HÀNH**\n",
    "## Sequence Representation trong RNN (Integer Encoding, One-hot Encoding, Padding, Truncation, Embedding)\n",
    "\n",
    "### **1. Mục tiêu bài thực hành**\n",
    "- Hiểu cách dữ liệu dạng chuỗi (text) được biến đổi thành dạng số để đưa vào mô hình học sâu (Deep Learning).\n",
    "- Thực hành các kỹ thuật biểu diễn chuỗi phổ biến trong RNN:\n",
    "  - Integer Encoding\n",
    "  - One-hot Encoding\n",
    "  - Padding\n",
    "  - Truncation\n",
    "  - Word Embedding\n",
    "- Thấy được sự khác biệt giữa các phương pháp mã hoá và lý do tại sao Embedding được sử dụng trong mô hình NLP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64953bae",
   "metadata": {},
   "source": [
    "## Nội dung chính\n",
    "\n",
    "1. Thiết lập dữ liệu mẫu và import thư viện\n",
    "2. Tạo vocabulary (word2idx / idx2word)\n",
    "3. Integer encoding\n",
    "4. One-hot encoding (ví dụ)\n",
    "5. Padding & Truncation\n",
    "6. Tạo Embedding và kiểm tra\n",
    "7. Forward qua RNN (chỉ forward)\n",
    "8. Một bước training demo (next-token prediction)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f70970",
   "metadata": {},
   "source": [
    "## 1) Thiết lập & dữ liệu mẫu\n",
    "\n",
    "Giải thích: Khởi tạo dữ liệu đầu vào (một vài câu), import thư viện cần thiết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9772b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: ['I Can Do It', 'I Try So Hard']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import thư viện và dữ liệu mẫu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List\n",
    "\n",
    "# Dữ liệu mẫu (nhỏ, dễ theo dõi)\n",
    "sentences = [\"I Can Do It\", \"I Try So Hard\"]\n",
    "\n",
    "print(\"Sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ef4f1",
   "metadata": {},
   "source": [
    "## 2) Tạo vocabulary (Integer Encoding)\n",
    "\n",
    "Giải thích: Tạo tập từ vựng (unique tokens), ánh xạ từ→index và index→từ. Reserve index 0 cho token `<PAD>` để tiện padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7835a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: ['Can', 'Do', 'Hard', 'I', 'It', 'So', 'Try']\n",
      "word2idx: {'Can': 1, 'Do': 2, 'Hard': 3, 'I': 4, 'It': 5, 'So': 6, 'Try': 7, '<PAD>': 0}\n",
      "idx2word: {1: 'Can', 2: 'Do', 3: 'Hard', 4: 'I', 5: 'It', 6: 'So', 7: 'Try', 0: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Tạo vocab\n",
    "tokens = \" \".join(sentences).split()\n",
    "unique_tokens = sorted(set(tokens))\n",
    "\n",
    "# word2idx: từ -> index. index 0 dành cho <PAD>.\n",
    "word2idx = {word: idx + 1 for idx, word in enumerate(unique_tokens)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "\n",
    "# idx2word: index -> từ (hữu ích khi debug)\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "print(\"Unique tokens:\", unique_tokens)\n",
    "print(\"word2idx:\", word2idx)\n",
    "print(\"idx2word:\", idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6675f",
   "metadata": {},
   "source": [
    "## 3) Integer encoding\n",
    "\n",
    "Giải thích: Chuyển mỗi câu thành danh sách index theo `word2idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de818161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentences: ['I Can Do It', 'I Try So Hard']\n",
      "Integer encoded: [[4, 1, 2, 5], [4, 7, 6, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Integer encode sentences\n",
    "integer_encoded: List[List[int]] = []\n",
    "for sent in sentences:\n",
    "    ints = [word2idx[word] for word in sent.split()]\n",
    "    integer_encoded.append(ints)\n",
    "\n",
    "print(\"Original sentences:\", sentences)\n",
    "print(\"Integer encoded:\", integer_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9e46a",
   "metadata": {},
   "source": [
    "## 4) One-hot encoding (ví dụ)\n",
    "\n",
    "Giải thích: One-hot tạo vector nhị phân cho mỗi token. Thường ít dùng trực tiếp cho DL do tính sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5aa797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (including <PAD>): 8\n",
      "\n",
      "One-hot vectors for the first sentence:\n",
      "Index 4 ('I') -> tensor([0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Index 1 ('Can') -> tensor([0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Index 2 ('Do') -> tensor([0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Index 5 ('It') -> tensor([0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: One-hot encoding example\n",
    "vocab_size = len(word2idx)  # bao gồm <PAD>\n",
    "def one_hot_encode(index: int, vocab_size: int) -> torch.Tensor:\n",
    "    vec = torch.zeros(vocab_size, dtype=torch.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "print(\"Vocab size (including <PAD>):\", vocab_size)\n",
    "print(\"\\nOne-hot vectors for the first sentence:\")\n",
    "for idx in integer_encoded[0]:\n",
    "    print(f\"Index {idx} ('{idx2word[idx]}') ->\", one_hot_encode(idx, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30605226",
   "metadata": {},
   "source": [
    "## 5) Padding sequences\n",
    "\n",
    "Giải thích: Để batch các sequence có độ dài khác nhau, ta padding token `<PAD>` (index 0) để đưa về cùng chiều dài."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d35e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor sequences (before padding): [tensor([4, 1, 2, 5]), tensor([4, 7, 6, 3])]\n",
      "\n",
      "Padded sequences (batch, seq_len):\n",
      " tensor([[4, 1, 2, 5],\n",
      "        [4, 7, 6, 3]])\n",
      "Padded shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Padding\n",
    "tensor_sequences = [torch.tensor(seq, dtype=torch.long) for seq in integer_encoded]\n",
    "padded_sequences = pad_sequence(tensor_sequences, batch_first=True, padding_value=word2idx[\"<PAD>\"])\n",
    "\n",
    "print(\"Tensor sequences (before padding):\", tensor_sequences)\n",
    "print(\"\\nPadded sequences (batch, seq_len):\\n\", padded_sequences)\n",
    "print(\"Padded shape:\", padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f8286",
   "metadata": {},
   "source": [
    "## 6) Truncation (cắt ngắn)\n",
    "\n",
    "Giải thích: Nếu muốn giới hạn chiều dài tối đa để tiết kiệm bộ nhớ hoặc phù hợp với mô hình, ta có thể cắt ngắn (truncate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe1162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated sequences (max_len=2): [[4, 1], [4, 7]]\n",
      "Padded truncated sequences: tensor([[4, 1],\n",
      "        [4, 7]])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Truncation example\n",
    "max_len = 2\n",
    "truncated = [seq[:max_len] for seq in integer_encoded]\n",
    "\n",
    "tensor_trunc = [torch.tensor(seq, dtype=torch.long) for seq in truncated]\n",
    "padded_trunc = pad_sequence(tensor_trunc, batch_first=True, padding_value=word2idx[\"<PAD>\"])\n",
    "\n",
    "print(\"Truncated sequences (max_len={}):\".format(max_len), truncated)\n",
    "print(\"Padded truncated sequences:\", padded_trunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7608d",
   "metadata": {},
   "source": [
    "## 7) Embedding layer\n",
    "\n",
    "Giải thích: Embedding ánh xạ index thành vector dense (học được). Sử dụng `padding_idx` để embedding của PAD không bị cập nhật."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622e79db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape (num_embeddings, embedding_dim): torch.Size([8, 8])\n",
      "Embedded output shape (batch, seq_len, emb_dim): torch.Size([2, 4, 8])\n",
      "Example embedded vector (sentence 0, token 0): tensor([ 0.3942,  0.7725, -0.2003,  0.5454, -1.5207, -0.8954, -2.2208, -0.6201],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Embedding\n",
    "embedding_dim = 8\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=word2idx[\"<PAD>\"])\n",
    "\n",
    "embedded = embedding(padded_sequences)  # shape: (batch, seq_len, embedding_dim)\n",
    "\n",
    "print(\"Embedding matrix shape (num_embeddings, embedding_dim):\", embedding.weight.shape)\n",
    "print(\"Embedded output shape (batch, seq_len, emb_dim):\", embedded.shape)\n",
    "print(\"Example embedded vector (sentence 0, token 0):\", embedded[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c32e9",
   "metadata": {},
   "source": [
    "## 8) RNN forward (chỉ forward)\n",
    "\n",
    "Giải thích: Đưa embedding vào RNN để quan sát output shapes. Ở đây dùng `batch_first=True` nên input shape là (batch, seq_len, features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca932ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN out shape (batch, seq_len, hidden_size): torch.Size([2, 4, 16])\n",
      "RNN hidden shape (num_layers, batch, hidden_size): torch.Size([1, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: RNN forward\n",
    "hidden_size = 16\n",
    "rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "rnn_out, rnn_hidden = rnn(embedded)\n",
    "\n",
    "print(\"RNN out shape (batch, seq_len, hidden_size):\", rnn_out.shape)\n",
    "print(\"RNN hidden shape (num_layers, batch, hidden_size):\", rnn_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075bfc3",
   "metadata": {},
   "source": [
    "## 9) Một bước training demo (Next-token prediction)\n",
    "\n",
    "Giải thích: Chuẩn bị targets bằng cách shift input sang trái (target tại time t là token ở t+1). Dùng CrossEntropyLoss với `ignore_index` để bỏ qua PAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f599fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training step done. Loss: 2.2267966270446777\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: One training step demo\n",
    "input_indices = padded_sequences  # (batch, seq_len)\n",
    "\n",
    "# Prepare targets by shifting left (next-token)\n",
    "targets = torch.zeros_like(input_indices)\n",
    "targets[:, :-1] = input_indices[:, 1:]\n",
    "targets[:, -1] = word2idx[\"<PAD>\"]\n",
    "\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        self.rnn = nn.RNN(input_size=emb_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.rnn(emb)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "model = SimpleRNNModel(vocab_size=vocab_size, emb_dim=embedding_dim, hidden_dim=hidden_size, padding_idx=word2idx[\"<PAD>\"])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<PAD>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# One training step\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "logits = model(input_indices)  # (batch, seq_len, vocab_size)\n",
    "B, S, V = logits.shape\n",
    "loss = criterion(logits.view(B*S, V), targets.view(B*S))\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"One training step done. Loss:\", loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
