{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2754e8",
   "metadata": {},
   "source": [
    "### **Bài thực hành 3: Bắt đầu với Hugging Face**\n",
    "**Tên sinh viên:** [Tên của bạn]\n",
    "**Mã số sinh viên:** [MSSV của bạn]\n",
    "**Lớp:** [Lớp của bạn]\n",
    "\n",
    "---\n",
    "### **Exercise 2: Tinh chỉnh (Finetuning) một mô hình đã được huấn luyện trước cho bài toán phân loại văn bản nhị phân**\n",
    "\n",
    "Trong bài tập này, chúng ta sẽ thực hiện một quy trình hoàn chỉnh để tinh chỉnh một mô hình ngôn ngữ đã được huấn luyện trước (pre-trained model) cho một tác vụ cụ thể: phân loại cảm xúc trên bộ dữ liệu đánh giá phim IMDB. Đây là một ví dụ kinh điển của bài toán phân loại văn bản nhị phân (tích cực/tiêu cực)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79587a2",
   "metadata": {},
   "source": [
    "#### **Bước 1 & 2: Tải thư viện và bộ dữ liệu**\n",
    "\n",
    "Đầu tiên, chúng ta cần các thư viện `datasets` để tải dữ liệu và `evaluate` để tính toán các độ đo. Bộ dữ liệu \"imdb\" là một bộ dữ liệu tiêu chuẩn chứa các bài đánh giá phim và nhãn tương ứng (0 cho tiêu cực, 1 cho tích cực).\n",
    "\n",
    "Để quá trình huấn luyện diễn ra nhanh chóng, chúng ta sẽ chỉ lấy một tập con nhỏ của dữ liệu để làm ví dụ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bda640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Tải bộ dữ liệu IMDB\n",
    "print(\"Đang tải bộ dữ liệu IMDB...\")\n",
    "dataset = load_dataset(\"imdb\")\n",
    "print(\"Tải dữ liệu thành công!\")\n",
    "\n",
    "# Để tiết kiệm thời gian, chúng ta sẽ tạo một tập dữ liệu con nhỏ hơn\n",
    "# Lấy 1000 mẫu cho tập huấn luyện và 500 mẫu cho tập kiểm tra\n",
    "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "print(\"\\nKích thước tập huấn luyện con:\", len(small_train_dataset))\n",
    "print(\"Kích thước tập kiểm tra con:\", len(small_test_dataset))\n",
    "print(\"\\nVí dụ một mẫu dữ liệu:\")\n",
    "print(small_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c74e80",
   "metadata": {},
   "source": [
    "#### **Bước 3: Tải mô hình Pre-trained và Tokenizer**\n",
    "\n",
    "Chúng ta sẽ sử dụng `distilbert-base-uncased`, một phiên bản nhỏ hơn và nhanh hơn của BERT, rất phù hợp cho việc tinh chỉnh. `AutoTokenizer` sẽ tự động tải tokenizer tương ứng với mô hình, và `AutoModelForSequenceClassification` sẽ tải kiến trúc mô hình với một lớp phân loại ở trên cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57643f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tên của mô hình pre-trained\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Tải tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tải mô hình với 2 nhãn (tiêu cực, tích cực)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "print(\"Đã tải xong tokenizer và mô hình.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e9a50",
   "metadata": {},
   "source": [
    "#### **Bước 4: Tiền xử lý dữ liệu**\n",
    "\n",
    "Mô hình không thể hiểu văn bản thô. Chúng ta cần chuyển đổi văn bản thành các con số mà mô hình có thể xử lý. Quá trình này được gọi là **tokenization**. Chúng ta sẽ tạo một hàm để tokenize văn bản và áp dụng nó cho toàn bộ bộ dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm tiền xử lý\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize văn bản, cắt bớt nếu dài hơn 512 token\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# Áp dụng hàm tiền xử lý cho tập train và test\n",
    "tokenized_train_dataset = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = small_test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "print(\"\\nMột mẫu dữ liệu sau khi tokenize:\")\n",
    "print(tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f78cba",
   "metadata": {},
   "source": [
    "#### **Bước 5 & 6: Định nghĩa tham số huấn luyện và tạo đối tượng Trainer**\n",
    "\n",
    "`TrainingArguments` là một lớp chứa tất cả các siêu tham số cho quá trình huấn luyện, chẳng hạn như learning rate, số epoch, kích thước batch,...\n",
    "\n",
    "`Trainer` là một lớp API cấp cao của Hugging Face giúp đơn giản hóa vòng lặp huấn luyện và đánh giá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa các tham số huấn luyện\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",              # Thư mục lưu kết quả\n",
    "    evaluation_strategy=\"epoch\",         # Đánh giá sau mỗi epoch\n",
    "    learning_rate=2e-5,                  # Tốc độ học\n",
    "    per_device_train_batch_size=16,      # Kích thước batch cho tập train\n",
    "    per_device_eval_batch_size=16,       # Kích thước batch cho tập test\n",
    "    num_train_epochs=3,                  # Số epoch huấn luyện\n",
    "    weight_decay=0.01,                   # Giảm trọng số để tránh overfitting\n",
    ")\n",
    "\n",
    "# Tải độ đo accuracy\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Định nghĩa hàm tính toán độ đo\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Tạo đối tượng Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Bắt đầu quá trình fine-tuning\n",
    "print(\"\\nBắt đầu quá trình tinh chỉnh mô hình...\")\n",
    "trainer.train()\n",
    "print(\"Hoàn tất tinh chỉnh!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00c5f7",
   "metadata": {},
   "source": [
    "#### **Bước 7: Đánh giá mô hình đã được tinh chỉnh**\n",
    "\n",
    "Sau khi huấn luyện, chúng ta cần đánh giá hiệu suất của mô hình trên tập dữ liệu kiểm tra (test set) để xem nó hoạt động tốt đến mức nào trên dữ liệu chưa từng thấy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện đánh giá trên tập test\n",
    "print(\"\\nĐang đánh giá mô hình trên tập kiểm tra...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n--- Kết quả đánh giá ---\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Lấy dự đoán trên tập test để vẽ ma trận nhầm lẫn\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = tokenized_test_dataset[\"label\"]\n",
    "\n",
    "# Tính toán ma trận nhầm lẫn\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Vẽ ma trận nhầm lẫn\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Tiêu cực', 'Tích cực'], yticklabels=['Tiêu cực', 'Tích cực'])\n",
    "plt.xlabel('Nhãn dự đoán')\n",
    "plt.ylabel('Nhãn thực tế')\n",
    "plt.title('Ma trận nhầm lẫn (Confusion Matrix)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6287fe9",
   "metadata": {},
   "source": [
    "**Báo cáo và phân tích kết quả:**\n",
    "\n",
    "1.  **Hiệu suất mô hình:** Dựa vào kết quả từ hàm `evaluate()`, chúng ta có thể thấy độ chính xác (accuracy) của mô hình trên tập dữ liệu kiểm tra. Một mô hình được tinh chỉnh tốt thường sẽ đạt độ chính xác cao (ví dụ: trên 85-90% cho bài toán này, ngay cả với một tập dữ liệu con). Điều này cho thấy mô hình đã học được cách phân biệt giữa các bài đánh giá phim tích cực và tiêu cực.\n",
    "\n",
    "2.  **Phân tích Ma trận nhầm lẫn (Confusion Matrix):**\n",
    "    *   **True Positives (TP)** và **True Negatives (TN)** (các giá trị trên đường chéo chính) cho biết số lượng mẫu được mô hình phân loại đúng. Giá trị càng cao càng tốt.\n",
    "    *   **False Positives (FP)** và **False Negatives (FN)** (các giá trị không nằm trên đường chéo chính) biểu thị số lượng mẫu bị phân loại sai. Giá trị càng thấp càng tốt.\n",
    "    *   Nhìn vào ma trận, chúng ta có thể đánh giá xem mô hình có xu hướng nhầm lẫn loại cảm xúc nào hơn. Ví dụ, nếu số FN cao, nghĩa là mô hình thường dự đoán sai các mẫu tích cực thành tiêu cực.\n",
    "\n",
    "**Kết luận:**\n",
    "Qua bài tập này, chúng ta đã thực hiện thành công việc tinh chỉnh một mô hình ngôn ngữ lớn cho tác vụ phân loại văn bản nhị phân. Bắt đầu từ một mô hình `distilbert-base-uncased` có kiến thức tổng quát, chúng ta đã \"chuyên môn hóa\" nó để hiểu sắc thái trong các bài đánh giá phim và đạt được hiệu suất phân loại tốt trên dữ liệu thực tế. Quy trình này cho thấy sức mạnh của học chuyển giao (transfer learning) trong lĩnh vực xử lý ngôn ngữ tự nhiên.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
